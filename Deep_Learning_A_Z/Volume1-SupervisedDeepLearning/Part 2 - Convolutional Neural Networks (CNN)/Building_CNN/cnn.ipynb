{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize CNN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Rishabh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "#Step 1 - Convolution step - no of feature maps = 32 and window is of size 3*3\n",
    "classifier.add(Convolution2D(filters=32, kernel_size=(3,3),input_shape=(64,64,3),activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2 - Pooling step : Max pooling because taking max, window pool size 2*2 -- reduces complexity and computations\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3 - Flattening\n",
    "classifier.add(Flatten()) # input layer to hidden- fully connected layer\n",
    "# what happens when img directly flattened without sonv and pooling step - spatial info is lost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4 - Full Connection layer - 128 general choice because lot of input nodes\n",
    "classifier.add(Dense(units= 128, activation='relu'))\n",
    "\n",
    "classifier.add(Dense(units= 1, activation='sigmoid')) #output layer - binary outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "WARNING:tensorflow:From C:\\Users\\Rishabh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/5\n",
      "8000/8000 [==============================] - 2244s 280ms/step - loss: 0.3935 - acc: 0.8152 - val_loss: 0.6941 - val_acc: 0.7730\n",
      "Epoch 2/5\n",
      "8000/8000 [==============================] - 2459s 307ms/step - loss: 0.1443 - acc: 0.9439 - val_loss: 1.2249 - val_acc: 0.7615\n",
      "Epoch 3/5\n",
      "8000/8000 [==============================] - 27583s 3s/step - loss: 0.0768 - acc: 0.9727 - val_loss: 1.3249 - val_acc: 0.7545\n",
      "Epoch 4/5\n",
      "8000/8000 [==============================] - 35234s 4s/step - loss: 0.0541 - acc: 0.9811 - val_loss: 1.6463 - val_acc: 0.7416\n",
      "Epoch 5/5\n",
      "8000/8000 [==============================] - 2333s 292ms/step - loss: 0.0423 - acc: 0.9856 - val_loss: 1.6133 - val_acc: 0.7560\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d5e2a62fd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##image augmentation -- rotate, flip,shear etc - lot more material to train - reduce overfitting\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255) #rescale image of test set\n",
    "\n",
    "train_set = train_datagen.flow_from_directory(\n",
    "        'dataset/training_set',\n",
    "        target_size=(64, 64),# less pixels - less information of pictures - so advisable is 128 \n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "        'dataset/test_set',\n",
    "        target_size=(64,64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    " \n",
    "classifier.fit_generator(\n",
    "        train_set,\n",
    "        steps_per_epoch=8000, #800o images in training set\n",
    "        epochs=5,# because of time constraints\n",
    "        validation_data=test_set,\n",
    "        validation_steps=2000) # 2000 images in test set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is a case of overfitting\n",
    "\n",
    "classifier = Sequential()\n",
    "classifier.add(Convolution2D(filters=32, kernel_size=(3,3),input_shape=(64,64,3),activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#adding 2nd conv layer to avoid overfitting\n",
    "classifier.add(Convolution2D(filters=32, kernel_size=(3,3),activation='relu'))\n",
    "\n",
    "classifier.add(Flatten()) # input layer to hidden- fully connected layer\n",
    "#Step 4 - Full Connection layer - 128 general choice because lot of input nodes\n",
    "classifier.add(Dense(units= 128, activation='relu'))\n",
    "\n",
    "classifier.add(Dense(units= 1, activation='sigmoid')) #output layer - binary outcome\n",
    "classifier.compile(optimizer='adam',loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "Epoch 1/5\n",
      "8000/8000 [==============================] - 2302s 288ms/step - loss: 0.3445 - acc: 0.8348 - val_loss: 0.7948 - val_acc: 0.7686\n",
      "Epoch 2/5\n",
      "8000/8000 [==============================] - 2280s 285ms/step - loss: 0.0789 - acc: 0.9713 - val_loss: 1.2128 - val_acc: 0.7700\n",
      "Epoch 3/5\n",
      "8000/8000 [==============================] - 2312s 289ms/step - loss: 0.0447 - acc: 0.9850 - val_loss: 1.4054 - val_acc: 0.7578\n",
      "Epoch 4/5\n",
      "8000/8000 [==============================] - 2313s 289ms/step - loss: 0.0323 - acc: 0.9895 - val_loss: 1.4090 - val_acc: 0.7724\n",
      "Epoch 5/5\n",
      "8000/8000 [==============================] - 2493s 312ms/step - loss: 0.0255 - acc: 0.9915 - val_loss: 1.4246 - val_acc: 0.7776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d5e193f828>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##image augmentation -- rotate, flip,shear etc - lot more material to train - reduce overfitting\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255) #rescale image of test set\n",
    "\n",
    "train_set = train_datagen.flow_from_directory(\n",
    "        'dataset/training_set',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "        'dataset/test_set',\n",
    "        target_size=(64,64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    " \n",
    "classifier.fit_generator(\n",
    "        train_set,\n",
    "        steps_per_epoch=8000, #800o images in training set\n",
    "        epochs=5,\n",
    "        validation_data=test_set,\n",
    "        validation_steps=2000) # 2000 images in test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image1 = image.load_img('dataset/single_prediction/cat_or_dog_1.jpg',target_size = (64,64))\n",
    "test_image2 = image.load_img('dataset/single_prediction/cat_or_dog_2.jpg',target_size = (64,64))\n",
    "#3rd dimension also needed\n",
    "test_image1 = image.img_to_array(test_image1)\n",
    "test_image2 = image.img_to_array(test_image2)  \n",
    "\n",
    "\n",
    "#classifier.predict(test_image1) #error here 4D required\n",
    "#add new dimension to make it work- for batch whether single or more \n",
    "test_image1 = np.expand_dims(test_image1, axis=0) # now 4d - 1,64,64,3\n",
    "test_image2 = np.expand_dims(test_image2, axis=0) # now 4d - 1,64,64,3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cats': 0, 'dogs': 1}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict(test_image1)\n",
    "classifier.predict(test_image2)\n",
    "train_set.class_indices #check what is which\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict(test_image1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict(test_image2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
