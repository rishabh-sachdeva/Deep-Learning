{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Artificial Neural Network\n",
    "\n",
    "# Part 1 - Data Preprocessing\n",
    "\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Importing the dataset\n",
    "dataset = pd.read_csv('Churn_Modelling.csv')\n",
    "X = dataset.iloc[:, 3:13]\n",
    "y = dataset.iloc[:, 13]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  \n",
       "0          1               1        101348.88  \n",
       "1          0               1        112542.58  \n",
       "2          1               0        113931.57  \n",
       "3          0               0         93826.63  \n",
       "4          1               1         79084.10  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    1\n",
       "3    0\n",
       "4    0\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.values\n",
    "y = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Categorical data encoding\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelEncoder_geo = LabelEncoder()\n",
    "X[:,1] = labelEncoder_geo.fit_transform(X[:,1])\n",
    "\n",
    "labelEncoder_gen = LabelEncoder()\n",
    "X[:,2] = labelEncoder_geo.fit_transform(X[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dummy variables for category : country\n",
    "onehotencoder = OneHotEncoder(categorical_features = [1])\n",
    "X = onehotencoder.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[:,1:] # to avoid dummy variable trap : 1 can be determined by other 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting training set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train, y_test = train_test_split(X,y, test_size =0.2, random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 11)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0000000e+00, 0.0000000e+00, 6.1900000e+02, 0.0000000e+00,\n",
       "       4.2000000e+01, 2.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "       1.0000000e+00, 1.0000000e+00, 1.0134888e+05])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating, Improving and Tuning ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "##including k cross validation\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier():\n",
    "    classifier = Sequential()\n",
    "    #adding input layer and first hidden layer\n",
    "    #general concept : no. of hidden layers =  avg. of no. of nodes in input layer and output layer = (11 + 1)/2\n",
    "    classifier.add(Dense(units = 6,init = 'uniform', activation = 'relu',input_dim=11 ))\n",
    "    classifier.add(Dropout(p=0.1)) # add dropout to first hidden layer - 1 neuron deactivates every iteration\n",
    "    #second hidden layer\n",
    "    classifier.add(Dense(units = 6,init = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dropout(p=0.1)) # add dropout to second hidden layer\n",
    "    classifier.add(Dense(units = 1,init = 'uniform', activation = 'sigmoid' ))\n",
    "    classifier.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    return classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KerasClassifier(build_fn=build_classifier,batch_size = 10, nb_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Rishabh\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rishabh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=6, activation=\"relu\", input_dim=11, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n",
      "C:\\Users\\Rishabh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \n",
      "C:\\Users\\Rishabh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=6, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  \n",
      "C:\\Users\\Rishabh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\Rishabh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, activation=\"sigmoid\", kernel_initializer=\"uniform\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 487us/step - loss: 0.4910 - acc: 0.7971\n",
      "800/800 [==============================] - 1s 1ms/step\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 440us/step - loss: 0.5032 - acc: 0.7961\n",
      "800/800 [==============================] - 1s 677us/step\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 512us/step - loss: 0.5056 - acc: 0.7954\n",
      "800/800 [==============================] - 1s 759us/step\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 524us/step - loss: 0.4972 - acc: 0.7971\n",
      "800/800 [==============================] - 1s 720us/step\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 485us/step - loss: 0.5029 - acc: 0.7937\n",
      "800/800 [==============================] - 1s 715us/step\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 546us/step - loss: 0.4951 - acc: 0.7943\n",
      "800/800 [==============================] - 1s 765us/step\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 434us/step - loss: 0.4968 - acc: 0.7967\n",
      "800/800 [==============================] - 1s 798us/step\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 520us/step - loss: 0.4941 - acc: 0.7957\n",
      "800/800 [==============================] - 1s 1ms/step\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 5s 653us/step - loss: 0.4900 - acc: 0.7957\n",
      "800/800 [==============================] - 1s 1ms/step\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 483us/step - loss: 0.4959 - acc: 0.7954\n",
      "800/800 [==============================] - 1s 852us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.78625   , 0.79      , 0.8       , 0.7825    , 0.81625   ,\n",
       "       0.81      , 0.7875    , 0.79375   , 0.79875   , 0.79499999])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies = cross_val_score(estimator=classifier, X=X_train, y=y_train, cv=10, n_jobs=1)\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7959999969601632"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010105690620981692"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies.std() # variance, its not bad, high variance means overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning the ANN - find best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier_grid(optimizer_arg):\n",
    "    classifier = Sequential()\n",
    "    #adding input layer and first hidden layer\n",
    "    #general concept : no. of hidden layers =  avg. of no. of nodes in input layer and output layer = (11 + 1)/2\n",
    "    classifier.add(Dense(units = 6,init = 'uniform', activation = 'relu',input_dim=11 ))\n",
    "    #classifier.add(Dropout(p=0.1)) # add dropout to first hidden layer - 1 neuron deactivates every iteration\n",
    "    #second hidden layer\n",
    "    classifier.add(Dense(units = 6,init = 'uniform', activation = 'relu'))\n",
    "    #classifier.add(Dropout(p=0.1)) # add dropout to second hidden layer\n",
    "    classifier.add(Dense(units = 1,init = 'uniform', activation = 'sigmoid' ))\n",
    "    classifier.compile(optimizer=optimizer_arg, loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KerasClassifier(build_fn=build_classifier_grid)\n",
    "parameters = {'batch_size':[25,32], \n",
    "              'nb_epoch':[100,500],\n",
    "              'optimizer_arg':['adam','rmsprop']                 \n",
    "             }\n",
    "grid_search = GridSearchCV(estimator=classifier, \n",
    "                           param_grid=parameters,\n",
    "                           scoring='accuracy',cv=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rishabh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=6, activation=\"relu\", input_dim=11, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n",
      "C:\\Users\\Rishabh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=6, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  \n",
      "C:\\Users\\Rishabh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, activation=\"sigmoid\", kernel_initializer=\"uniform\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 313us/step - loss: 0.5613 - acc: 0.7974\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 331us/step - loss: 0.5544 - acc: 0.7967\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 382us/step - loss: 0.5553 - acc: 0.7956\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 295us/step - loss: 0.5511 - acc: 0.7971\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 297us/step - loss: 0.5514 - acc: 0.7933\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 299us/step - loss: 0.5789 - acc: 0.7933\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 331us/step - loss: 0.5673 - acc: 0.7953\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 313us/step - loss: 0.5773 - acc: 0.7950\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 313us/step - loss: 0.5743 - acc: 0.7953\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 368us/step - loss: 0.5649 - acc: 0.7961\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 317us/step - loss: 0.5723 - acc: 0.7965\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 328us/step - loss: 0.5899 - acc: 0.7954\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 332us/step - loss: 0.5580 - acc: 0.7954\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 334us/step - loss: 0.5839 - acc: 0.7965\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 335us/step - loss: 0.6024 - acc: 0.7928\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 374us/step - loss: 0.6038 - acc: 0.7931\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 341us/step - loss: 0.6014 - acc: 0.7954\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 347us/step - loss: 0.5551 - acc: 0.7962\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 353us/step - loss: 0.6217 - acc: 0.7950\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 377us/step - loss: 0.5995 - acc: 0.7954\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 374us/step - loss: 0.5776 - acc: 0.7964\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 379us/step - loss: 0.5529 - acc: 0.7969\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 385us/step - loss: 0.6061 - acc: 0.7933\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 390us/step - loss: 0.5753 - acc: 0.7969\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 400us/step - loss: 0.5794 - acc: 0.7919\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 408us/step - loss: 0.6568 - acc: 0.7937\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 406us/step - loss: 0.5471 - acc: 0.7969\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 459us/step - loss: 0.5445 - acc: 0.7961\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 596us/step - loss: 0.5622 - acc: 0.7947\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 6s 778us/step - loss: 0.5598 - acc: 0.7953\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 589us/step - loss: 0.5804 - acc: 0.7967\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 548us/step - loss: 0.5683 - acc: 0.7967\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 604us/step - loss: 0.5760 - acc: 0.7940\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 553us/step - loss: 0.5791 - acc: 0.7974\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 516us/step - loss: 0.5913 - acc: 0.7929\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 460us/step - loss: 0.5703 - acc: 0.7936\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 485us/step - loss: 0.5633 - acc: 0.7969\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 465us/step - loss: 0.6054 - acc: 0.7949\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 467us/step - loss: 0.5704 - acc: 0.7953\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 493us/step - loss: 0.6035 - acc: 0.7949\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - ETA: 0s - loss: 0.6102 - acc: 0.794 - 3s 475us/step - loss: 0.5916 - acc: 0.7956\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 477us/step - loss: 0.5908 - acc: 0.7947\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 490us/step - loss: 0.5938 - acc: 0.7947\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 501us/step - loss: 0.5945 - acc: 0.7957\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 499us/step - loss: 0.5756 - acc: 0.7937\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 512us/step - loss: 0.5865 - acc: 0.7918\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 513us/step - loss: 0.5790 - acc: 0.7969\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 517us/step - loss: 0.5895 - acc: 0.7947\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 529us/step - loss: 0.5861 - acc: 0.7949\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 533us/step - loss: 0.6122 - acc: 0.7940\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 613us/step - loss: 0.6423 - acc: 0.7956\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 535us/step - loss: 0.6185 - acc: 0.7964\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 622us/step - loss: 0.6202 - acc: 0.7937\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 551us/step - loss: 0.5972 - acc: 0.7968\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 548us/step - loss: 0.6068 - acc: 0.7929\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 545us/step - loss: 0.6013 - acc: 0.7932\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 568us/step - loss: 0.6259 - acc: 0.7965\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 558us/step - loss: 0.6267 - acc: 0.7936\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 566us/step - loss: 0.5917 - acc: 0.7950\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 572us/step - loss: 0.6072 - acc: 0.7958\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 603us/step - loss: 0.5966 - acc: 0.7940\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 602us/step - loss: 0.5956 - acc: 0.7940\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 622us/step - loss: 0.5732 - acc: 0.7956\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 612us/step - loss: 0.6090 - acc: 0.7960\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 5s 627us/step - loss: 0.5942 - acc: 0.7914\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 5s 629us/step - loss: 0.5794 - acc: 0.7944\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 5s 636us/step - loss: 0.5907 - acc: 0.7965\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 5s 645us/step - loss: 0.5715 - acc: 0.7962\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 5s 650us/step - loss: 0.5986 - acc: 0.7946\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 5s 663us/step - loss: 0.5790 - acc: 0.7950\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 5s 651us/step - loss: 0.6036 - acc: 0.7958\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 5s 668us/step - loss: 0.6233 - acc: 0.7949\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 5s 664us/step - loss: 0.5782 - acc: 0.7956\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 5s 674us/step - loss: 0.6129 - acc: 0.7956\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 5s 671us/step - loss: 0.6233 - acc: 0.7914\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 5s 682us/step - loss: 0.6093 - acc: 0.7922\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 5s 678us/step - loss: 0.6092 - acc: 0.7954\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 5s 704us/step - loss: 0.5910 - acc: 0.7946\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 5s 692us/step - loss: 0.6301 - acc: 0.7947\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 5s 718us/step - loss: 0.5897 - acc: 0.7954\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 5s 671us/step - loss: 0.5464 - acc: 0.7950\n"
     ]
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)\n",
    "best_params = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.796"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 25, 'nb_epoch': 100, 'optimizer_arg': 'adam'}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
